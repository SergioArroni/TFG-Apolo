The growing threat of Adversarial Machine Learning (AML) attacks is posing a significant
        challenge for the effectiveness of Intrusion Detection Systems (IDS).
        In this paper, we propose \textit{Apollon}, a novel defence system that can protect IDS against
        AML evasion and extraction attacks.
        \textit{Apollon} leverages a set of heterogeneous classifiers to detect intrusions and applies a
        \textit{Multi-Armed Bandits (MAB)} model to dynamically select the optimal classifier or ensemble of classifiers
        for each input.
        Therefore, \textit{Apollon} can prevent attackers from learning the IDS behaviour and generating
        adversarial examples that can evade the IDS detection.
        We evaluate \textit{Apollon} on several of the most popular and recent datasets, and show that it can successfully
        detect attacks without compromising its performance on normal inputs.
        We also demonstrate that \textit{Apollon} can prevent attackers from learning the IDS behaviour in realistic
        training times.
        Our results suggest that \textit{Apollon} is an effective and efficient defence system against AML attacks in IDS.
    
