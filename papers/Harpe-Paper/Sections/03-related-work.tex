In this section, we will review the different \textit{IDS} classifiers and their scores for the selected datasets.
These classifiers will be utilized later to simulate the \textit{SDP IDS}.
Furthermore, we will detail the various types of \textit{AML} attacks that are employed in this context.

\subsection{Intrusion Detection Systems classifiers}\label{subsec:intrusion-detection-systems-classifiers}

As the number and sophistication of malware threats continue to grow, it is increasingly important to have effective
\textit{IDS} in place to protect network systems.
To ensure the effectiveness of \textit{IDS} systems, researchers conduct a range of studies and literature reviews to
identify and address potential vulnerabilities.
These studies are ongoing and are crucial in the ongoing development of \textit{IDS} systems to keep pace with the
evolving threat landscape.

Tables~\ref{tab:ids-classifiers-cic-ids2017},~\ref{tab:ids-classifiers-cse-cic-ids2018},
~\ref{tab:ids-classifiers-cic-ddos2019}, and~\ref{tab:ids-classifiers-unsw-nb15} show the \textit{IDS} classifiers and
their scores (accuracy, F1, and AUC) for the \textit{CIC-IDS2017}, \textit{CSE-CIC-IDS2018}, \textit{CIC-DDoS2019}, and
\textit{UNSW-NB15} datasets, respectively.
In these datasets and the most commonly used datasets (\textit{KDDD 99} and \textit{NSL-KDD}), the most commonly used
and best-performing classifiers are \textit{Random Forest}, \textit{Decision Trees}, and \textit{SVM}.
\textit{Random Forest}~\cite{zhang2008random}, in particular, has gained popularity due to its ability to handle large
datasets and its robust performance when dealing with noise and missing values in the data.
\textit{Decision Trees}~\cite{amor2004naive} are also popular due to their interpretability and simplicity, as they
allow for clear visualization of the decision-making process.
\textit{SVMs}~\cite{mohammadi2021} are favored for their ability to handle high-dimensional data and their versatility
in dealing with different types of classification tasks.
Overall, these classifiers have demonstrated strong performance and are frequently used in the field of \textit{IDS}.

\begin{table}
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|r|rrr|l|}
            \hline
            \textbf{Classifier} & \textbf{Accuracy} & \textbf{F1 score} & \textbf{AUC} & \textbf{Ref}                                                                                     \\ \hline
            IGAN-IDS            & 99.79             & 99.79             & 99.98        & ~\cite{huang2020igan}                                                                            \\
            ANN                 & 99.28             & 99.17             & 99.28        & ~\cite{maseer2021benchmarking}                                                                   \\
            Fuzziness-based NN  & 99.61             & 99.57             & 99.83        & ~\cite{huang2020igan, wu2022rtids}                                                               \\
            CNN                 & 99.48             & 99.44             & 99.94        & ~\cite{huang2020igan, maseer2021benchmarking}                                                    \\
            RTIDS               & 99.35             & 99.17             & 98.83        & ~\cite{wu2022rtids}                                                                              \\
            MLP                 & 99.46             & 99.46             & 99.41        & ~\cite{pujari2022comparative, rosay2022multi}                                                    \\
            ROS + MLP           & 99.55             & 99.55             & 99.88        & ~\cite{huang2020igan}                                                                            \\
            Random Forest       & 99.79             & 99.78             & 99.98        & ~\cite{pujari2022comparative, huang2020igan, Abdulhammed2019, maseer2021benchmarking, faker2019} \\
            Decision Trees      & 99.62             & 99.57             & 99.56        & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking}                             \\
            SMOTE + SVM         & 97.00             & 97.04             & 98.97        & ~\cite{huang2020igan}                                                                            \\
            SVM                 & 96.97             & 96.99             & 98.98        & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking, faker2019, wu2022rtids}     \\
            ROS + SVM           & 96.98             & 97.04             & 98.96        & ~\cite{huang2020igan}                                                                            \\
            RUS + SVM           & 96.45             & 96.55             & 98.96        & ~\cite{huang2020igan}                                                                            \\
            Naive Bayes         & 93.90             & 93.53             & 97.49        & ~\cite{huang2020igan, maseer2021benchmarking, faker2019}                                         \\ \hline
        \end{tabular}
    }\caption{Performance of the \textit{IDSs} classifiers on the \textit{CIC-IDS2017} dataset.}\label{tab:ids-classifiers-cic-ids2017}
\end{table}

\begin{table}
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|r|rrr|l|}
            \hline
            \textbf{Classifier} & \textbf{Accuracy} & \textbf{F1 score} & \textbf{AUC} & \textbf{Ref}                                                                                     \\ \hline
            MLP                 & 62.00             & 89.00             & 100.00       & ~\cite{pujari2022comparative, rosay2022multi}                                                    \\
            Random Forest       & 92.00             & 94.00             & 100.00       & ~\cite{pujari2022comparative, huang2020igan, Abdulhammed2019, maseer2021benchmarking, faker2019} \\
            Decision Trees      & 88.00             & 91.00             & 100.00       & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking}                             \\
            SVM                 & 61.00             & 66.00             & 100.00       & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking, faker2019, wu2022rtids}     \\ \hline
        \end{tabular}
    }\caption{Performance of the \textit{IDSs} classifiers on the \textit{CSE-CIC-IDS2018} dataset.}\label{tab:ids-classifiers-cse-cic-ids2018}
\end{table}

\begin{table}
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|r|rrr|l|}
            \hline
            \textbf{Classifier} & \textbf{Accuracy} & \textbf{F1 score} & \textbf{AUC} & \textbf{Ref}                                                                                 \\ \hline
            Fuzziness-based NN  & 95.55             & 95.50             & 95.63        & ~\cite{huang2020igan, wu2022rtids}                                                           \\
            RTIDS               & 98.58             & 98.48             & 98.66        & ~\cite{wu2022rtids}                                                                          \\
            SVM                 & 94.02             & 94.88             & 94.24        & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking, faker2019, wu2022rtids} \\ \hline
        \end{tabular}
    }\caption{Performance of the \textit{IDSs} classifiers on the \textit{CIC-DDoS2019} dataset.}\label{tab:ids-classifiers-cic-ddos2019}
\end{table}

\begin{table}
    \resizebox{\columnwidth}{!}{%
        \begin{tabular}{|r|rrr|l|}
            \hline
            \textbf{Classifier} & \textbf{Accuracy} & \textbf{F1 score} & \textbf{AUC} & \textbf{Ref}                                                                                     \\ \hline
            IGAN-IDS            & 82.53             & 82.86             & 97.09        & ~\cite{huang2020igan}                                                                            \\
            Fuzziness-based NN  & 81.21             & 78.58             & 97.02        & ~\cite{huang2020igan, wu2022rtids}                                                               \\
            CNN                 & 80.52             & 76.61             & 96.72        & ~\cite{huang2020igan, maseer2021benchmarking}                                                    \\
            MLP                 & 72.00             & 73.00             & 90.00        & ~\cite{pujari2022comparative, rosay2022multi}                                                    \\
            ROS + MLP           & 76.13             & 76.97             & 96.29        & ~\cite{huang2020igan}                                                                            \\
            Random Forest       & 88.86             & 77.28             & 95.18        & ~\cite{pujari2022comparative, huang2020igan, Abdulhammed2019, maseer2021benchmarking, faker2019} \\
            Decision Trees      & 73.52             & 76.36             & 86.56        & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking}                             \\
            SMOTE + SVM         & 71.50             & 73.77             & 94.44        & ~\cite{huang2020igan}                                                                            \\
            SVM                 & 68.49             & 70.13             & 95.15        & ~\cite{pujari2022comparative, huang2020igan, maseer2021benchmarking, faker2019, wu2022rtids}     \\
            ROS + SVM           & 68.32             & 70.00             & 95.08        & ~\cite{huang2020igan}                                                                            \\
            RUS + SVM           & 67.16             & 70.45             & 94.98        & ~\cite{huang2020igan}                                                                            \\
            Naive Bayes         & 61.80             & 65.27             & 90.13        & ~\cite{huang2020igan, maseer2021benchmarking, faker2019}                                         \\ \hline
        \end{tabular}
    }\caption{Performance of the \textit{IDSs} classifiers on the \textit{UNSW-NB15} dataset.\label{tab:ids-classifiers-unsw-nb15}}
\end{table}

\subsection{Adversarial Machine Learning Attacks}\label{subsec:adversarial-machine-learning-attacks}

\textit{IDSs} that use \textit{AI} are more effective at detecting threats than those that rely on traditional
rule-based approaches, but they are also more vulnerable to adversarial attacks.
These attacks involve manipulating the input data used to train the \textit{AI} model in such a way that it fails to
correctly identify a threat.
\textit{Adversarial Machine Learning} attacks can be difficult to detect and prevent, which makes them attractive to
attackers.
Additionally, as \textit{AI} techniques become more widely used in cyber security, there is a growing incentive for
attackers to develop more sophisticated adversarial attacks to evade detection.

\subsubsection{White-box Attacks}\label{subsubsec:white-box-attacks}
The \textit{white-box} attacks are the most effective type of \textit{AML} attacks because they allow the attacker to
have full knowledge of the \textit{IDS} classifier and the training data.
This level of knowledge allows the attacker to craft highly targeted and sophisticated attacks that can bypass the
system's defenses and achieve their desired outcome.
However, \textit{white-box} attacks are also the least realistic type of attack because they require the attacker to
have extensive knowledge of the system and its vulnerabilities, which is often not feasible.
In most cases, the attacker will only have partial or limited knowledge of the system, making \textit{white-box}
attacks infeasible.
As a result, \textit{white-box} attacks are relatively rare in practice and are typically only used in highly targeted
and carefully planned operations.

Some of the most commonly used \textit{white-box} attacks on \textit{IDS} are
\textit{Fast Gradient Sign Method (FGSM)}~\cite{fgsm}, \textit{DeepFool}~\cite{deepfool},
\textit{Carlini \& Wagner attack (C\&W)}~\cite{carlini}, \textit{Jacobian-based Saliency Map Attack (JSMA)}~\cite{jsma},
\textit{Basic Iterative Method (BIM)}~\cite{bim}, and the \textit{Projected Gradient Descent (PGD)}~\cite{pgd}.

The \textit{FGSM} attack generates adversarial examples by adding a small perturbation to the input data using the
\textit{gradient-based} method.
\textit{BIM} and \textit{PGD} are variants of the \textit{FGSM} attack that iteratively add perturbations to the input
data to generate more effective adversarial examples.
\textit{DeepFool} is a type of untargeted attack that involves calculating the minimum distance between the original
input and the decision boundary of a machine learning model.
The \textit{JSMA} is a method for generating adversarial examples that uses the model's \textit{Jacobian}, or forward
derivatives, to iteratively perturb the features or components of the input.
Finally, the \textit{C\&W} attack is a method for generating adversarial examples by formulating the search for an
adversarial sample as an optimization problem.
The objective of this optimization problem is to minimize the distance between the original input and the adversarial
example, while also ensuring that the model incorrectly classifies the adversarial example.


\subsubsection{Grey/Black-box Attacks}\label{subsubsec:grey-black-box-attacks}
\textit{Grey/Black-box} are more realistic than \textit{white-box} attacks because they do not require the attacker to
have full knowledge of the \textit{IDS} classifier and the training data.
However, \textit{grey/black-box} attacks are generally less efficient than \textit{white-box} attacks because the
attacker's lack of knowledge about the system limits their ability to craft highly targeted and sophisticated attacks.
Instead, the attacker must rely on more general techniques that may be less effective at bypassing the system's
defenses.

Many \textit{grey/black-box} attacks use \textit{Generative Adversarial Networks (GANs)}~\cite{goodfellow2020generative}
to generate adversarial examples.
\textit{GANs} are a type of \textit{Machine Learning} model that consists of two neural networks: a generator network
and a discriminator network.
The generator network is trained to produce synthetic data that is similar to the real data, while the discriminator
network is trained to distinguish between real and synthetic data.

In the context of \textit{grey/black-box} attacks, the generator network can be used to produce adversarial examples
that are designed to bypass the target system's defenses.
The attacker may have access to the system's model scores or just a binary output indicating whether the input was
accepted or rejected.
This information can be used to guide the training of the generator network and improve its ability to produce
effective adversarial examples.

Some of the most recent \textit{grey/black-box} attacks on \textit{IDS} are
\textit{attackGAN}~\cite{zhao2021attackgan}, \textit{DIGFuPAS}~\cite{duy2021digfupas},
\textit{IDSGAN}~\cite{lin2022idsgan}, \textit{VulnerGAN}~\cite{liu2022vulnergan},
\textit{Zeroth-order optimization (ZOO) attack}~\cite{chen2017zoo}, \textit{Boundary attack}~\cite{brendel2017decision},
and \textit{Hop Skip Jump Attack (HSJA)}~\cite{chen2019boundary}.

\textit{ZOO} is a \textit{grey/black-box} score-based attack that directly estimates the gradients for generating
adversarial traffic.
\textit{Boundary attack} and \textit{HSJA} are \textit{grey/black-box} decision-based attacks that only knows
a binary output indicating whether the input was accepted or rejected.

The \textit{IDSGAN}, \textit{attackGAN}, and \textit{DIGFuPAS} are \textit{grey/black-box} attacks that use
\textit{Wasserstein GAN (WGAN)} to generate adversarial traffic.

\textit{Wasserstein GAN (WGAN)}~\cite{gulrajani2017improved} is a variant of \textit{GANs} that uses a different
objective function for training the generator network.
\textit{WGAN} introduces a new objective function called the \textit{Wasserstein} distance, which is used to train the
generator network.
The \textit{Wasserstein} distance is a measure of the distance between two probability distributions and has several
desirable properties, such as being smooth and continuous.
Some of the most recent \textit{WGANs} uses the \textit{Gradient Penalty}~\cite{gulrajani2017improved} to improve
the convergence of the training process.

However, attacks with \textit{WGANs}, like \textit{IDSGAN}, generate adversarial examples by training a generator
with random noise as input.
This approach is not effective because the generator network alters key characteristics of an attack in an effort to
evade detection~\cite{usama2019generative}.
This is not a viable tactic, as these characteristics are crucial for the attack to be successful.
