As computer networks continue to grow in size and complexity, the need for effective security measures becomes
increasingly critical.
Intrusion Detection Systems (IDS) have been developed to address this challenge, providing a means of monitoring
network traffic and identifying potential security threats.
These systems can analyze network traffic and identify potential security threats such as malware, network intrusions,
and denial of service attacks.
However, the increasing complexity and diversity of network traffic have made it difficult to accurately classify
network traffic using traditional rule-based IDS systems~\cite{thakkar2020review}.

To overcome these limitations, Machine Learning (ML) techniques have been widely adopted in IDS for network traffic
classification.
These techniques leverage the power of statistical models and algorithms to automatically learn and detect anomalous
network traffic patterns, which are indicative of security threats.

ML-based IDS systems offer several advantages over traditional rule-based systems, including higher accuracy, better
scalability, and more robustness to evolving network threats~\cite{abdallah2022intrusion, maseer2021benchmarking}.
However, they also pose new challenges, particularly in terms of security.
One of the main challenges is the susceptibility of ML models to Adversarial Machine Learning (AML)
attacks~\cite{huang2011adversarial}.

AML attacks are a type of cyber-attack that aims to manipulate ML models by feeding them carefully crafted input data,
called adversarial examples.
These examples are designed to cause misclassification or incorrect predictions, which can be exploited by attackers to
bypass the security measures of IDS systems~\cite{zhao2021attackgan, lin2022idsgan, liu2022vulnergan}.

Attackers create adversarial examples by utilizing information obtained from the targeted IDS, including its responses
to specific inputs.
This information is used to train a model capable of generating adversarial traffic that remains undetectable by the
IDS classifier.

As ML-based IDS systems become more prevalent, the threat of Adversarial Machine Learning (AML) attacks becomes more
significant~\cite{duy2021digfupas}.
Therefore, it is crucial to develop effective defense mechanisms to mitigate the impact of these attacks and ensure the
reliability and robustness of IDS systems.

In this paper, we propose a new robust defense system against Adversarial Machine Learning attacks on Intrusion
Detection Systems called \textit{Apollon}.
\textit{Apollon} serves to safeguard IDS from attackers by obstructing their ability to generate adversarial traffic through
learning from the behavior of the IDS.

\textit{Apollon} utilizes a diverse range of classifiers to detect intrusions and employs a \textit{Multi-Armed Bandits (MAB)}
with \textit{Thompson sampling} to select the optimal classifier or a combination of classifiers in real-time for each input,
enabling it to achieve this objective without compromising its performance on traditional network traffic.

In this way, \textit{Apollon} can prevent attackers from learning the behavior of the IDS in realistic training times, adding a
layer of uncertainty to the IDS behavior that makes it more difficult for attackers to detect the IDS behavior and
generate adversarial traffic.

The structure of the paper is as follows.
Section ~\ref{sec:background} provides an overview of the main concepts and techniques used in this paper.
Section ~\ref{sec:related-work} discusses the related work in the field of AML attacks and IDS classifiers.
Section ~\ref{sec:proposal} presents the proposed defense system, \textit{Apollon}.
Section ~\ref{sec:evaluation} presents the experimental evaluation of \textit{Apollon}.
Finally, Section ~\ref{sec:conclusions-and-future-work} concludes the paper and discusses future work.